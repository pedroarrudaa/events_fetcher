# ğŸ¯ Events Platform: Hackathons & Conferences

A comprehensive platform for discovering, collecting, and displaying hackathons and conferences with intelligent data collection, enrichment, and web dashboard. Built with FastAPI backend, React frontend, and advanced AI-powered data processing.

![Events Platform](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)
![Python](https://img.shields.io/badge/Python-3.11-blue)
![React](https://img.shields.io/badge/React-18.2-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-orange)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue)

## ğŸŒŸ Features

### ğŸ¤– Intelligent Data Collection
- **Multi-Source Fetching**: Automated data collection from Devpost, MLH, HackerEarth, Hackathon.com, Eventbrite, Tavily, and more
- **Smart URL Tracking**: Advanced deduplication with `collected_urls` table and `is_enriched` flag
- **AI-Powered Enrichment**: OpenAI GPT-4 for extracting detailed event information
- **Performance Optimization**: Skip already processed URLs to save API credits

### ğŸ¯ Advanced Filtering & Processing
- **Location-Based Filtering**: Smart matching for SF/Bay Area, NYC, and Remote events
- **Date Filtering**: Automatic filtering for future events only
- **Quality Validation**: GPT-powered validation to ensure legitimate events
- **Duplicate Detection**: URL-based deduplication across all sources

### ğŸ“Š Web Dashboard
- **Unified API**: Combines hackathons and conferences from database
- **Real-time Filtering**: Filter by type, location, and status
- **Responsive Design**: Beautiful UI built with Tailwind CSS
- **Production Ready**: Configured for deployment on Render + Vercel

## ğŸ— Architecture

```
events-platform/
â”œâ”€â”€ ğŸš€ Data Collection Pipelines
â”‚   â”œâ”€â”€ hackathon_fetcher/           # Hackathon collection pipeline
â”‚   â”‚   â”œâ”€â”€ main.py                  # Main execution script
â”‚   â”‚   â”œâ”€â”€ sources/                 # Data source scrapers
â”‚   â”‚   â”‚   â”œâ”€â”€ devpost.py          # Devpost hackathons
â”‚   â”‚   â”‚   â”œâ”€â”€ mlh.py              # Major League Hacking
â”‚   â”‚   â”‚   â”œâ”€â”€ hackerearth.py      # HackerEarth challenges
â”‚   â”‚   â”‚   â”œâ”€â”€ hackathon_com.py    # Hackathon.com events
â”‚   â”‚   â”‚   â””â”€â”€ eventbrite.py       # Eventbrite hackathons
â”‚   â”‚   â”œâ”€â”€ enrichers/              # AI-powered data enrichment
â”‚   â”‚   â”‚   â””â”€â”€ gpt_extractor.py    # OpenAI GPT-4 enrichment
â”‚   â”‚   â””â”€â”€ utils/                  # Utility functions
â”‚   â”‚       â””â”€â”€ firecrawl.py        # Optional web scraping
â”‚   â””â”€â”€ conference_fetcher/          # Conference collection pipeline
â”‚       â”œâ”€â”€ conference_fetcher.py    # Main execution script
â”‚       â”œâ”€â”€ sources/                 # Conference data sources
â”‚       â”‚   â”œâ”€â”€ tavily_discovery.py # AI-powered discovery
â”‚       â”‚   â””â”€â”€ conference_google.py # Google search integration
â”‚       â”œâ”€â”€ enrichers/              # AI enrichment
â”‚       â”‚   â””â”€â”€ gpt_extractor.py    # Conference-specific enrichment
â”‚       â””â”€â”€ queries.txt             # Search queries configuration
â”œâ”€â”€ ğŸ—„ï¸ Database & Backend
â”‚   â”œâ”€â”€ database_utils.py           # PostgreSQL models & utilities
â”‚   â”œâ”€â”€ backend.py                  # FastAPI application
â”‚   â””â”€â”€ event_filters.py            # Location & date filtering
â”œâ”€â”€ ğŸ¨ Frontend Dashboard
â”‚   â”œâ”€â”€ frontend/                   # React application
â”‚   â”‚   â”œâ”€â”€ src/components/         # UI components
â”‚   â”‚   â””â”€â”€ package.json           # Frontend dependencies
â”œâ”€â”€ ğŸš€ Deployment
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ Procfile                   # Render deployment
â”‚   â”œâ”€â”€ render.yaml                # Infrastructure config
â”‚   â””â”€â”€ runtime.txt                # Python version
â””â”€â”€ output/                        # Generated data files
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- PostgreSQL database
- OpenAI API key
- Optional: Firecrawl API key, Tavily API key

### 1. Environment Setup

Create a `.env` file in the root directory:

```bash
# Required
DATABASE_URL="postgresql://user:password@host:port/database"
OPENAI_API_KEY="sk-your-openai-api-key"

# Optional (for enhanced functionality)
FIRECRAWL_API_KEY="fc-your-firecrawl-key"
TAVILY_API_KEY="tvly-your-tavily-key"

# Frontend (for production)
FRONTEND_URL="https://your-frontend-domain.com"
```

### 2. Backend Setup

```bash
# Install Python dependencies
pip install -r requirements.txt

# Start backend server
python backend.py
```

### 3. Data Collection

#### Collect Hackathons
```bash
# Collect 50 hackathons per source with enrichment
python hackathon_fetcher/main.py

# The script will:
# 1. Fetch URLs from all sources (Devpost, MLH, HackerEarth, etc.)
# 2. Save URLs to collected_urls table
# 3. Enrich only new URLs (is_enriched=False)
# 4. Apply location/date filtering
# 5. Save results to database and files
```

#### Collect Conferences
```bash
# Collect conferences with AI-powered discovery
python conference_fetcher/conference_fetcher.py

# Features:
# - Smart search query management
# - Tavily AI-powered discovery
# - Force re-enrichment option
# - Advanced filtering and validation
```

### 4. Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

### 5. Access the Platform

- **Frontend Dashboard**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

## ğŸ¤– Data Collection Pipeline

### URL Collection & Tracking

The platform uses an intelligent URL tracking system to optimize performance and reduce API costs:

```python
# collected_urls table structure
{
    "url": "https://example.com/hackathon",
    "source_type": "hackathon",  # or "conference"
    "is_enriched": False,        # True after AI enrichment
    "timestamp_collected": "2024-01-15T10:30:00Z",
    "url_metadata": {"title": "AI Hackathon 2024"}
}
```

### Smart Processing Logic

1. **Collection Phase**: Gather URLs from all sources
2. **Deduplication**: Skip previously collected URLs
3. **Enrichment Phase**: Process only new URLs (`is_enriched=False`)
4. **Validation**: Apply location, date, and quality filters
5. **Storage**: Save to database with proper status tracking

### Configuration Options

#### Hackathon Fetcher
```python
# In hackathon_fetcher/main.py
fetcher.run(
    limit_per_source=50,      # URLs per source
    enable_enrichment=True    # AI enrichment on/off
)
```

#### Conference Fetcher
```python
# In conference_fetcher/conference_fetcher.py
fetcher.run(
    limit_per_source=2,           # URLs per source
    max_results_per_query=2,      # Results per search query
    force_reenrich=False          # Force re-enrichment of existing URLs
)
```

### Force Re-enrichment

For testing or updating existing data:

```python
# Enable force re-enrichment in conference_fetcher.py
fetcher.run(force_reenrich=True)

# This will:
# 1. Select 1-3 already enriched URLs
# 2. Re-process them with latest AI models
# 3. Update existing database records
```

## ğŸ¯ Filtering & Validation

### Location-Based Filtering

The platform intelligently filters events based on target locations:

- **San Francisco/Bay Area**: SF, San Francisco, Bay Area, Silicon Valley, etc.
- **New York City**: NYC, New York, Manhattan, Brooklyn, etc.
- **Remote/Virtual**: Online, Virtual, Remote events

### Date Filtering

- Automatically filters out past events
- Supports various date formats
- Handles date ranges and single dates

### Quality Validation

- GPT-powered validation to identify legitimate events
- Filters out low-quality or spam entries
- Maintains high data quality standards

## ğŸ“Š API Endpoints

### Events API

- `GET /events` - Get all events
- `GET /events?type_filter=hackathon` - Filter by type
- `GET /events?location_filter=san francisco` - Filter by location
- `GET /events?status_filter=validated` - Filter by status
- `GET /health` - Health check with database status

### Response Format

```json
{
  "title": "AI/ML Hackathon 2024",
  "type": "hackathon",
  "location": "San Francisco, CA",
  "start_date": "2024-02-15",
  "end_date": "2024-02-17",
  "url": "https://example.com/event",
  "status": "validated",
  "remote": false,
  "speakers": ["John Doe", "Jane Smith"],
  "sponsors": ["TechCorp", "AI Ventures"],
  "themes": ["AI", "Machine Learning"]
}
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `DATABASE_URL` | âœ… | PostgreSQL connection string |
| `OPENAI_API_KEY` | âœ… | OpenAI API key for enrichment |
| `FIRECRAWL_API_KEY` | âŒ | Optional web scraping service |
| `TAVILY_API_KEY` | âŒ | Optional AI search for conferences |
| `FRONTEND_URL` | âŒ | Frontend URL for CORS (production) |

### Database Schema

The platform uses three main tables:

#### `hackathons` & `conferences`
```sql
CREATE TABLE hackathons (
    id UUID PRIMARY KEY,
    name VARCHAR NOT NULL,
    url VARCHAR UNIQUE NOT NULL,
    start_date VARCHAR,
    end_date VARCHAR,
    location VARCHAR,
    remote BOOLEAN DEFAULT FALSE,
    description TEXT,
    speakers JSON,
    sponsors JSON,
    themes JSON,
    source VARCHAR,
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### `collected_urls` (URL Tracking)
```sql
CREATE TABLE collected_urls (
    url VARCHAR PRIMARY KEY,
    source_type VARCHAR NOT NULL,
    is_enriched BOOLEAN DEFAULT FALSE,
    timestamp_collected TIMESTAMP DEFAULT NOW(),
    url_metadata JSON
);
```

## ğŸš€ Performance Optimizations

### API Credit Savings
- **Smart URL Tracking**: Only process new URLs
- **Efficient Deduplication**: Skip previously collected URLs
- **Selective Enrichment**: Process only `is_enriched=False` entries
- **Batch Processing**: Optimize API calls for multiple events

### Processing Speed
- **Parallel Processing**: Concurrent API calls where possible
- **Intelligent Caching**: Database-backed URL tracking
- **Optimized Queries**: Efficient database operations
- **Error Handling**: Graceful failure recovery

### Resource Management
- **Memory Optimization**: Stream processing for large datasets
- **Rate Limiting**: Respect API rate limits
- **Connection Pooling**: Efficient database connections
- **Logging**: Comprehensive monitoring and debugging

## ğŸ§ª Testing & Validation

### Test Data Collection
```bash
# Test mode (limited to 1 event)
python hackathon_fetcher/main.py --test

# Force re-enrichment for testing
python conference_fetcher/conference_fetcher.py  # Set force_reenrich=True
```

### Health Checks
```bash
# Test backend
curl http://localhost:8000/health

# Test database connection
python -c "from database_utils import get_db_stats; print(get_db_stats())"
```

## ğŸš€ Deployment

### Option 1: Render + Vercel (Recommended)

1. **Backend on Render**
   - Connect GitHub repository
   - Use provided `Procfile` and `render.yaml`
   - Set all required environment variables

2. **Frontend on Vercel**
   - Connect GitHub repository
   - Set root directory to `frontend`
   - Add `REACT_APP_API_URL` environment variable

### Option 2: Docker

```bash
# Build and run with Docker Compose
docker-compose up --build
```

## ğŸ“ˆ Monitoring & Analytics

### Database Statistics
```python
from database_utils import get_db_stats
stats = get_db_stats()

# Returns:
{
    "hackathons": {"total": 150, "remote": 120, "recent_24h": 5},
    "conferences": {"total": 80, "remote": 60, "recent_24h": 3},
    "collected_urls": {
        "overall": {"total": 500, "enriched": 400, "pending": 100},
        "hackathon": {"total": 300, "enriched": 250, "pending": 50},
        "conference": {"total": 200, "enriched": 150, "pending": 50}
    }
}
```

### Performance Metrics
- Collection speed: ~6 minutes for 100 URLs
- Enrichment rate: 95%+ success rate
- API efficiency: Only new URLs processed
- Database performance: <50ms query times

## ğŸ›  Tech Stack

### Backend
- **FastAPI**: Modern Python web framework
- **SQLAlchemy**: PostgreSQL ORM
- **OpenAI GPT-4**: AI-powered data enrichment
- **Firecrawl**: Optional web scraping service
- **Tavily**: AI-powered search and discovery

### Frontend
- **React 18**: JavaScript library for building UIs
- **Tailwind CSS**: Utility-first CSS framework
- **Fetch API**: HTTP requests

### Database & Infrastructure
- **PostgreSQL**: Primary database with JSON support
- **Railway/Render**: Database and backend hosting
- **Vercel**: Frontend hosting and CDN

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™‹â€â™‚ï¸ Support

- ğŸ“– **Documentation**: Check individual README files in fetcher directories
- ğŸ› **Issues**: Open an issue on GitHub
- ğŸ’¬ **Discussions**: Use GitHub Discussions for questions

## ğŸ¯ Roadmap

- [ ] User authentication and personalization
- [ ] Event creation and editing interface
- [ ] Advanced search with faceted filters
- [ ] Email notifications for new events
- [ ] Calendar integration (Google Calendar, iCal)
- [ ] Mobile app development
- [ ] Real-time event updates
- [ ] Community features (reviews, ratings)

---

**Built with â¤ï¸ for the hackathon and conference community**

*Powered by AI â€¢ Optimized for Performance â€¢ Designed for Scale* 